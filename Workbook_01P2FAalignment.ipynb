{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P2FA Alginment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Katrina Kechun Li, 2023.3\n",
    "\n",
    "The code below is largely from Chenzi Xu's [tutorial](https://chenzixu.rbind.io/resources/1forcedalignment/), but adapted to my own workflow.\n",
    "\n",
    "All the codes (includes Terminal ones) is written in a way that can be directly run in this Ipython Notebook."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare sound files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "currentlang = \"Changsha\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My current working folder is in GitHub/0 PhD_working folder:\n",
    "\n",
    "1. run `p2fasound.praat` to segment annotated sounds&textgrids to individual files in `/1 individual`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Use sox to generate downsampled sound files, saved to `/downsample` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kechun/Documents/0_PhD_working_folder/Changsha/1 Individual\n"
     ]
    }
   ],
   "source": [
    "soundfolder = \"/Users/kechun/Documents/0_PhD_working_folder/\" + currentlang + \"/1 Individual\"\n",
    "%cd {soundfolder}\n",
    "!for i in *.wav; do sox \"$i\" -r 16k -b 16 -c 1 \"downsample/${i%.}\"; done"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the text files\n",
    "\n",
    "1. Check that all the transciptions have been listed in the latest annotation excel tab `record`. Copy the excel file to `/processtext`, and then run the following code. Some files will be generated in the folder.\n",
    "\n",
    "Remember to change the excel file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tf/xp1pp0c905qbfj8gl5gm79h80000gn/T/ipykernel_44802/3539112296.py:13: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df[\"text\"] = df['annotation'].str.replace('[^\\w\\s]','')\n"
     ]
    }
   ],
   "source": [
    "# After checking the 'record' tab in the annotating excel file, we processed it.\n",
    "# In the sheet, there should be four columns: Speaker, file, sentence will be used to generate 'tokenid', whereas the last column is 'transcription'. \n",
    "####### Change file name here #######\n",
    "filename = \"长沙话标注20231104.xlsx\"\n",
    "# filename = \"粤语标注230531.xlsx\"\n",
    "# filename = \"成都话标注230930.xlsx\"\n",
    "######################################\n",
    "import pandas as pd\n",
    "import os\n",
    "annofolder = \"/Users/kechun/Documents/P2FA_\" + str(currentlang.lower()) + \"/processtext\"\n",
    "fullname = os.path.join(annofolder,filename)\n",
    "df = pd.read_excel(fullname, sheet_name = \"record\")\n",
    "df[\"text\"] = df['annotation'].str.replace('[^\\w\\s]','')\n",
    "df.text = df.text.str.join(\" \")\n",
    "df[\"tokenid\"]=df['Speaker']+ df['file']+ df['sentence'] + \".wav\"\n",
    "output = df[['tokenid', 'text']]\n",
    "output.to_csv(os.path.join(annofolder, \"list.txt\"), sep = \" \", header = False, index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. From list.txt to generate individual text files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kechun/Documents/P2FA_chengdu/processtext\n"
     ]
    }
   ],
   "source": [
    "annofolder = \"/Users/kechun/Documents/P2FA_\" + str(currentlang.lower()) + \"/processtext\"\n",
    "%cd {annofolder}\n",
    "!cat list.txt | while read line || [ -n \"$line\" ]; do echo $line | awk '{$1=\"\"}1'| awk '{$1=$1}1' |awk '{gsub(/\"/, \"\")} 1' > $(cut -d \" \" -f1 <<< individualtxt/$line).txt; done < list.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Run the command below to check pronunciation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kechun/Documents/P2FA_chengdu/processtext\n"
     ]
    }
   ],
   "source": [
    "annofolder = \"/Users/kechun/Documents/P2FA_\" + str(currentlang.lower()) + \"/processtext\"\n",
    "%cd {annofolder}\n",
    "!bash checkpron.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Check the `missingwords.txt` as well as the `wordphones.txt` to see if all the characters used in the transcriptions have correct phonetic transcriptions. Modify `dictcopy` accordingly.\n",
    "\n",
    "5. Repeat Step 3 recursively until all issues are clear\n",
    "\n",
    "**In addition, make sure there is no empty lines in the dict file. Otherwise P2FA will report errors.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the P2FA\n",
    "1. Copy the sound files (from `/downsample`) and text files (from `/individualtext`) to `/run`\n",
    "\n",
    "2. Copy the `dictcopy` to `/run/model`, and rename as `dict`\n",
    "\n",
    "2. Make sure the Calign2textgrid.py document 'HOMEDIR' variable shows the right python (where `/run` folder is located)\n",
    "\n",
    "2. Make sure there is a folder `/textgrid`\n",
    "\n",
    "3. Run the code below in terminal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kechun/Documents/P2FA_chengdu/run\n"
     ]
    }
   ],
   "source": [
    "runfolder = \"/Users/kechun/Documents/P2FA_\" + str(currentlang.lower()) + \"/run/\"\n",
    "%cd {runfolder}\n",
    "!for i in *.wav; do python Calign2textgrid.py $i $i.txt textgrid/$i.TextGrid; done"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the recordings\n",
    "\n",
    "1. Move the original sound files (not the downsample one) to `/workflow/sound_original`\n",
    "\n",
    "2. Move the generated textgrid to `workflow/textgrid_original`\n",
    "\n",
    "3. Now move on to the file `Workbook_02processing.ipynb` to further process the files."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "e79691a9e4bc6bdcbdc684eff31eb98e99068d83ca035967ad235b3618ca5970"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
