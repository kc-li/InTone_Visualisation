{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workbook for Processing the P2FA forced alignment\n",
    "By Katrina Li 2023.4.27"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline\n",
    "1. Check the boundary\n",
    "\n",
    "    Use `Check_P2FA.praat`\n",
    "\n",
    "1. Modify the onset-rhyme boudnary, repetitively if needed\n",
    "\n",
    "    Use `modify_boundaries.praat`\n",
    "\n",
    "1. Generate the f0 tier\n",
    "\n",
    "     Use `generate_f0_tier.praat`\n",
    "\n",
    "1. Extract f0 and duration\n",
    "\n",
    "    Use `extract_acoustics.py` (cf. InTone_Visualisation)\n",
    "\n",
    "1. Modify the f0 boundary, repetitivel if needed\n",
    "\n",
    "    Use `modify_boundaries.praat`\n",
    "\n",
    "1. Check Visualitaion, mostly f0 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 8.0.4 (20230421.1958)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"426pt\" height=\"352pt\"\n",
       " viewBox=\"0.00 0.00 425.77 351.50\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 347.5)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-347.5 421.77,-347.5 421.77,4 -4,4\"/>\n",
       "<!-- CheckB -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>CheckB</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"120.5\" cy=\"-325.5\" rx=\"100.48\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"120.5\" y=\"-320.45\" font-family=\"Times,serif\" font-size=\"14.00\">Check the segmentation</text>\n",
       "</g>\n",
       "<!-- Generatef0 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>Generatef0</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"120.5\" cy=\"-252.5\" rx=\"83.08\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"120.5\" y=\"-247.45\" font-family=\"Times,serif\" font-size=\"14.00\">Generate the f0 tier</text>\n",
       "</g>\n",
       "<!-- CheckB&#45;&gt;Generatef0 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>CheckB&#45;&gt;Generatef0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M120.5,-307.31C120.5,-299.55 120.5,-290.18 120.5,-281.45\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"124,-281.53 120.5,-271.53 117,-281.53 124,-281.53\"/>\n",
       "</g>\n",
       "<!-- Modify -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>Modify</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"217,-36 0,-36 0,0 217,0 217,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"108.5\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">Modify the boundary (syllable or f0)</text>\n",
       "</g>\n",
       "<!-- Extract -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>Extract</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"120.5\" cy=\"-179.5\" rx=\"96.9\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"120.5\" y=\"-174.45\" font-family=\"Times,serif\" font-size=\"14.00\">Extract f0 and duration</text>\n",
       "</g>\n",
       "<!-- Modify&#45;&gt;Extract -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>Modify&#45;&gt;Extract</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" d=\"M109.81,-36.35C111.87,-63.78 115.91,-117.43 118.39,-150.4\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"114.95,-150.42 119.19,-160.13 121.93,-149.89 114.95,-150.42\"/>\n",
       "</g>\n",
       "<!-- Generatef0&#45;&gt;Extract -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>Generatef0&#45;&gt;Extract</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M120.5,-234.31C120.5,-226.55 120.5,-217.18 120.5,-208.45\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"124,-208.53 120.5,-198.53 117,-208.53 124,-208.53\"/>\n",
       "</g>\n",
       "<!-- Check -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>Check</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"274.5,-124.5 136.74,-106.5 274.5,-88.5 412.26,-106.5 274.5,-124.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"274.5\" y=\"-101.45\" font-family=\"Times,serif\" font-size=\"14.00\">Check the visualisation</text>\n",
       "</g>\n",
       "<!-- Extract&#45;&gt;Check -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>Extract&#45;&gt;Check</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M155.44,-162.39C179.31,-151.39 210.96,-136.8 235.62,-125.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"236.76,-128.29 244.38,-120.93 233.83,-121.93 236.76,-128.29\"/>\n",
       "</g>\n",
       "<!-- Check&#45;&gt;Modify -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>Check&#45;&gt;Modify</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" d=\"M247.83,-91.6C221.86,-78.07 181.97,-57.28 151.51,-41.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"153.47,-37.96 142.98,-36.45 150.23,-44.17 153.47,-37.96\"/>\n",
       "<text text-anchor=\"middle\" x=\"229.38\" y=\"-57.2\" font-family=\"Times,serif\" font-size=\"14.00\">problem</text>\n",
       "</g>\n",
       "<!-- Finish -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>Finish</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"326.5\" cy=\"-18\" rx=\"91.27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"326.5\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">Analyse the data in R</text>\n",
       "</g>\n",
       "<!-- Check&#45;&gt;Finish -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>Check&#45;&gt;Finish</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M284.04,-89.63C291.42,-77.35 301.82,-60.06 310.47,-45.66\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"313.98,-47.62 316.13,-37.25 307.98,-44.02 313.98,-47.62\"/>\n",
       "<text text-anchor=\"middle\" x=\"318\" y=\"-57.2\" font-family=\"Times,serif\" font-size=\"14.00\">good</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x10908cd90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "dot = Digraph(comment = 'Outline')\n",
    "dot.node(\"CheckB\",\"Check the segmentation\")\n",
    "dot.node(\"Modify\",\"Modify the boundary (syllable or f0)\",shape = \"box\")\n",
    "dot.node(\"Generatef0\",\"Generate the f0 tier\")\n",
    "dot.node(\"Extract\",\"Extract f0 and duration\")\n",
    "dot.node(\"Check\",\"Check the visualisation\",shape = \"diamond\")\n",
    "dot.node(\"Finish\",\"Analyse the data in R\")\n",
    "# connections\n",
    "dot.edge(\"CheckB\",\"Generatef0\")\n",
    "dot.edge(\"Generatef0\", \"Extract\")\n",
    "# dot.edge(\"Generatef0\", \"Modifyf0\")\n",
    "dot.edge(\"Modify\",\"Extract\",style = \"dashed\")\n",
    "dot.edge(\"Extract\",\"Check\")\n",
    "dot.edge(\"Check\",\"Finish\",label = \"good\")\n",
    "dot.edge(\"Check\",\"Modify\",label = \"problem\", style = \"dashed\")\n",
    "dot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisite\n",
    "\n",
    "Establish appropriate folder structure for each langauge. My folder structure is shown below. Note that the subfolders are created for intermediate stages."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "workflow/\n",
    "├── sound_original/\n",
    "│   └── S9dia2nDT4.wav\n",
    "├── textgrid_original/\n",
    "│   ├── discard/\n",
    "│   ├── later/\n",
    "│   ├── processed/\n",
    "│   └── S10dia1B2_checked.TextGrid\n",
    "├── textgrid_checked/\n",
    "│   ├── modify/\n",
    "│   └── processed/\n",
    "├── p2falog/\n",
    "│   └── S9dia2nDT4_log.txt\n",
    "└── textgrid_pitch_batch/\n",
    "    ├── discard/\n",
    "    ├── modify/\n",
    "    ├── S10dia1B2.PointProcess\n",
    "    └── S10dia1B2_checked.TextGrid\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Check the segmentation (syllable level)\n",
    "\n",
    "In this step, we check the segmentation returned from the P2FA forced alignment.\n",
    "\n",
    "Run the praat script `checkP2FA.praat`. This praat script will go through each boundary at onset/rhyme boundary, allowing you to accept the automatic marking or assign a new boundary.\n",
    "\n",
    "- Input: `textgrid_original/XXX.wav.Textgrid` files, and the associated wav files in `sound_original` folder.\n",
    "\n",
    "- Output: `textgrid_checked/XXX_checked.Textgrid` files with generated rhyme + syllable tier. The original files will be moved into `textgrid_original/processed` subfolder.\n",
    "\n",
    "For mac system, I recommended to combine with the use of App BetterTouchTool, so that you can specify short cut for the buttons of the scripts.\n",
    "\n",
    "After finishing checking the files, remember to move all the files into `textgrid_original/processed` folder."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify the boundary (f0 or syllable)\n",
    "\n",
    "There are two ways to organise the modify process.\n",
    "\n",
    "1. Put the files in the `/modify` folder, which can either be in `textgrid_checked` folder to modify onset-syllable boundarieds), or in `textgrid_pitch_batch` folder to modify the f0 boundaries.\n",
    "\n",
    "    Run the praat script `modify_boundaries.praat`, the go through the files in a folder\n",
    "\n",
    "2. Use `open_target_files` to open individual file in either `textgrid_checked` or `textgrid_pitch_batch`, and then manually saved to the same place"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A handy script: Move selected files\n",
    "1. In the `textgrid_original` folder, move files to unprocessed, so that some TextGrid will be processed later; Or more commonly, move all the files to `unprocessed` foler, and move files to be annotated out of thefolder. The code below demonstrates this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prerequisite\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "current_lang = \"Cantonese\"\n",
    "dir = os.path.join(\"/Users/kechun/Documents/0_PhD_working_folder\", str(current_lang), \"workflow\")\n",
    "\n",
    "######################## In checking the P2FA step#####################\n",
    "# directory = os.path.join(dir, \"textgrid_original/unprocessed\")\n",
    "# destination = os.path.join(dir, \"textgrid_original\")\n",
    "######################## In checking the pitch boundary step#####################\n",
    "directory = os.path.join(dir, \"textgrid_pitch_batch\")\n",
    "destination = os.path.join(dir, \"textgrid_pitch_batch/modify\")\n",
    "\n",
    "targetsentence = [\"AT\"]\n",
    "targetfocus = [\"1\",\"2\",\"3\",\"4\"]\n",
    "# targetid = [\"S15\"]\n",
    "for ifile in os.listdir(directory):\n",
    "    if ifile.endswith(\".TextGrid\"):\n",
    "        filename = ifile.split(\".\")[0]\n",
    "        parid = re.split(\"diaN?1?\",filename)[0]\n",
    "        condition = re.split(\"diaN?1?\",filename)[1]\n",
    "        tone = re.search(\"[A-F]T?\",condition).group(0)\n",
    "        focus = re.search(\"[1-5]a?\",condition).group(0)\n",
    "        if tone in targetsentence and focus in targetfocus:\n",
    "            shutil.move(os.path.join(directory,ifile), destination)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. For Condition4 files, we need an extra step of processing. We want to exclude the first part of the sentence so that our cheking workload can be reduced. \n",
    "\n",
    "    Move files from `/unprocessed` to `/old4`, then run the praat script `cut_condition4.praat`. After this, you will have the files saved to `textgrid_original` folder. You can follow the previosu steps.\n",
    "\n",
    "    Do remember to move the cutted files from `old4` to `old4/processed`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the f0 tier\n",
    "After checking the segmentation boudnaries, the next step is the modify the 'rhyme' tier to make it fit for f0 extraction.\n",
    "The code below will call the praat script `generate_f0_tier.praat`, replace the original rhyme tier with a f0 tiers, where initial and ending periods where no f0 is dectected are deleted.\n",
    "\n",
    "- Input: `/textgrid_check/XX_checked.TextGrid` files. Remember to change the langauge in the code below.\n",
    "\n",
    "- Output: `textgrid_pitch_batch/XX_checked.TextGrid` files. The original files will be moved into the subfolder `/textgrid_check/processed`.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current design is to iterate over the entire folder. Calling praat subprocessed does not seem a very elegant solution, however, the advange is that it can be combined with python function of moving processed files into another folders. When errors arise, we can know which file causes problem, adjust accordingly and continue with the rest files.\n",
    "The alternative way is to ask users to specify the desired processing file (commented code). But when there are too many files, this does not become economical.\n",
    "\n",
    "In either case, the idea is to avoid repetitive generation of this tier, as later on these files may be adjusted manually and we do not want to overwrite them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file will read specified files, and run the praat script\n",
    "import subprocess\n",
    "from itertools import product\n",
    "import os\n",
    "import shutil\n",
    "import parselmouth\n",
    "from parselmouth.praat import call\n",
    "import math\n",
    "\n",
    "################## Change the language###############\n",
    "current_lang = \"Cantonese\"\n",
    "dir = os.path.join(\"/Users/kechun/Documents/0_PhD_working_folder\", str(current_lang), \"workflow\")\n",
    "directory = os.path.join(dir, \"textgrid_checked\")\n",
    "destination = os.path.join(dir, \"textgrid_checked/processed\")\n",
    "# Open the sound\n",
    "directory_sound = os.path.join(dir, \"sound_original\")\n",
    "\n",
    "# par = [\"S3\",]\n",
    "# dia = [\"dia1\", \"dia1n\"]\n",
    "# sentence = [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"I\",\"AT\",\"DT\"]\n",
    "# focus = [\"1\",\"2\",\"3\",\"4\"]\n",
    "# element_list = list(product(par,dia,sentence,focus))\n",
    "\n",
    "# Argument to the script\n",
    "# The first three is to call the app and script\n",
    "# Arg1: filename\n",
    "# Arg2: textgriddir\n",
    "# Arg3: sounddir\n",
    "# Arg2: f0min (if 0, then the default two-pass pitch range calculation will be used)\n",
    "# Arg3: f0max (if 0, then the default two-pass pitch range calculatio will be used)\n",
    "# Other variables like file directory, the tiers can be modified\n",
    "# Output: the updated f0 \n",
    "for ifile in os.listdir(directory):\n",
    "    if ifile.endswith(\".TextGrid\"):\n",
    "        basename = ifile[:-17]\n",
    "        filename = basename + \"_checked\"\n",
    "# # for element in element_list:\n",
    "# #     fullname = ''.join(element)\n",
    "# #     filename = fullname + \"_checked\"\n",
    "    # Open the sound\n",
    "        soundname = os.path.join(directory_sound, basename + \".wav\")\n",
    "        sound = parselmouth.Sound(soundname)\n",
    "        # Calculate the best f0\n",
    "        # The first pass\n",
    "        pitch1 = call(sound, \"To Pitch\", 0.0, 50, 800)\n",
    "        min1 = call(pitch1, \"Get minimum\", 0, 0, \"Hertz\", \"None\")\n",
    "        max1 = call(pitch1, \"Get maximum\", 0, 0, \"Hertz\", \"None\")\n",
    "        q1 = call(pitch1, \"Get quantile\", 0, 0, 0.25, \"Hertz\")\n",
    "        q3 = call(pitch1, \"Get quantile\", 0, 0, 0.75, \"Hertz\")\n",
    "        q1 = math.floor(q1)\n",
    "        q3 = math.ceil(q3)\n",
    "        # The second pass\n",
    "        defaultf0floor = math.floor((0.7 * q1)/ 10) * 10\n",
    "        defaultf0ceiling = math.ceil((2.5 * q3)/ 10) * 10\n",
    "        # Run the script, not send, \n",
    "        subprocess.call([\"/Applications/Praat.app/Contents/MacOS/Praat\", \"--run\", \"scripts_praat/generate_f0_tier.praat\", filename, directory, directory_sound, str(defaultf0floor),str(defaultf0ceiling)])\n",
    "        path = filename + \".TextGrid\"\n",
    "        shutil.move(os.path.join(directory,path), destination)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract f0 and duration\n",
    "\n",
    "Open the script `extract_acoustics.py`, and specify the relevant parameters (e.g. the langauge to work on). This will extract needed parameters that are easy to analyse.\n",
    "\n",
    "- Input: `textgrid_pitch_batch/XXX.TextGrid` files, associated `PointProcess` or `Pitch` files if there are any. Also, a `Template.xlsx` provides the template of read speech to be able to compared to.\n",
    "\n",
    "- Output: `extract_acoustics_results/230530Cantonese_data.tsv` and `extract_acoustics_results/230530Cantonese_realf0_data.tsv`\n",
    "\n",
    "This script mainly makes use of the python package Parselmouth, and also relies on a prespecified template of the materials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [self, other]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [self, other]\n",
      "Index: []\n",
      "Number of files processed:  922\n",
      "REP dictionary\n",
      "啊\t7\n",
      "哦\t5\n",
      "阿\t1\n",
      "ADD dictionary\n",
      "spp\t152\n",
      "spg\t124\n",
      "好\t105\n",
      "一\t51\n",
      "定\t51\n",
      "呢\t33\n",
      "嘅\t30\n",
      "今\t26\n",
      "晚\t26\n",
      "饭\t26\n",
      "餸\t26\n",
      "食\t26\n",
      "出\t25\n",
      "戏\t25\n",
      "睇\t25\n",
      "我\t10\n",
      "哋\t10\n",
      "仲\t10\n",
      "係\t8\n",
      "谂\t7\n",
      "下\t7\n",
      "啦\t7\n",
      "你\t6\n",
      "點\t6\n",
      "解\t6\n",
      "开\t6\n",
      "部\t6\n",
      "旧\t6\n",
      "车\t6\n",
      "其\t4\n",
      "他\t4\n",
      "方\t4\n",
      "案\t4\n",
      "紧\t4\n",
      "依\t3\n",
      "家\t3\n",
      "生\t3\n",
      "意\t3\n",
      "咁\t3\n",
      "做\t3\n",
      "咩\t3\n",
      "先\t3\n",
      "得\t3\n",
      "嗰\t3\n",
      "五\t3\n",
      "十\t3\n",
      "几\t3\n",
      "分\t3\n",
      "真\t3\n",
      "丢\t3\n",
      "贾\t3\n",
      "都\t3\n",
      "可\t3\n",
      "以\t3\n",
      "留\t3\n",
      "学\t3\n",
      "事\t3\n",
      "啊\t2\n",
      "至\t2\n",
      "个\t1\n",
      "情\t1\n",
      "唔\t1\n",
      "咯\t0\n",
      "SFP dictionary\n",
      "咯\t4\n"
     ]
    }
   ],
   "source": [
    "%run extract_acoustics.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check visualisation\n",
    "\n",
    "Step I.\n",
    "\n",
    "Open `InTone_Visualisation.Rproj`. \n",
    "\n",
    "Open `Rcode_f0check/01f0clean.Rmd` and specify the data files to be read in (because the datafiles have date on it).\n",
    "\n",
    "- Input: the generated datafiles in `extract_acoustics_results`\n",
    "\n",
    "- Output: `X_flagfiles.csv` which contains all the files to check, and the visualisation of pitch contours in the folder `03figures`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step II.\n",
    "\n",
    "Use *Python* script below to move all the files into the `textgrid_pitch_batch/modify` folder, along with their pointprocess files (if not, then generate one). It is often needed to modify pointprocess files to correct the pitch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the textgrid files to modify folder\n",
    "# Prerequisite\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import re\n",
    "import pandas as pd\n",
    "import parselmouth\n",
    "from parselmouth.praat import call\n",
    "\n",
    "#################################################\n",
    "# read the flagfile csv\n",
    "# flagfiles = pd.read_csv(\"Rcode_f0check/Can_flagfiles.csv\")\n",
    "flagfiles = pd.read_csv(\"Rcode_analysis/Cantonese_dur_outliers.csv\")\n",
    "#################################################\n",
    "\n",
    "current_lang = \"Cantonese\"\n",
    "dir = os.path.join(\"/Users/kechun/Documents/0_PhD_working_folder\", str(current_lang), \"workflow\")\n",
    "directory = os.path.join(dir, \"textgrid_pitch_batch\")\n",
    "destination = os.path.join(dir, \"textgrid_pitch_batch/modify\")\n",
    "sounddirectory = os.path.join(dir,\"sound_original\")\n",
    "\n",
    "for index,row in flagfiles.iterrows():\n",
    "    file_to_move = row[\"filename\"]\n",
    "    filename = file_to_move + \"_checked.TextGrid\"\n",
    "    # print(filename)\n",
    "    # Read sound files\n",
    "    soundname = file_to_move + \".wav\"\n",
    "    sound = parselmouth.Sound(os.path.join(sounddirectory,soundname))\n",
    "    #Check if pointprocess exists\n",
    "    pointprocess = os.path.join(directory,file_to_move + \".PointProcess\")\n",
    "    pitch = os.path.join(directory,file_to_move + \".Pitch\")\n",
    "    if os.path.exists(pitch):\n",
    "        shutil.move(pitch,destination)\n",
    "    if os.path.exists(pointprocess):\n",
    "        shutil.move(pointprocess,destination)\n",
    "    else:\n",
    "        # Read the default f0 floor and ceilling\n",
    "        defaultf0floor = row[\"defaultf0floor\"]\n",
    "        defaultf0ceiling = row[\"defaultf0ceiling\"]\n",
    "        # generate PointProcesses files\n",
    "        pointprocess = call(sound, \"To PointProcess (periodic, cc)\", defaultf0floor,defaultf0ceiling)\n",
    "        # Save the pointproces file into the modify folder\n",
    "        pointprocess.save(os.path.join(destination,file_to_move + \".PointProcess\"))\n",
    "    shutil.move(os.path.join(directory,filename), destination)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step III.\n",
    "\n",
    "I will move all files back to the `textgrid_pitch_batch` folder, and rerun the `extract_acoustics.py` and the `Rcode_f0check/01f0clean.Rmd`. This is because using the pointprocesses files might result in new pitch parameters.\n",
    "\n",
    "Step IV.\n",
    "\n",
    "Run the `modify_boundaries.praat` to modify the boundaries."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "S1dia1nC2: duk very limited f0;\n",
    "S1dia1nI3: fan get creaky; the best pitch range might not be enough; need to generate pitch files!\n",
    "\n",
    "S1dia1nF2: 影  might just be curly.\n",
    "\n",
    "S1dia2nDT1: on need to generate pitch files, but couldn't finish this process\n",
    "S1dia2nDT2: the default pitch range seems OK, but why errors?\n",
    "\n",
    "\n",
    "In final data:\n",
    "delte S1dia1nF2_7, too much curly\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      filename chars  defaultf0floor  defaultf0ceiling\n",
      "261  S3dia1nC4  国, 读             140               670\n"
     ]
    }
   ],
   "source": [
    "# Read the flagfiles\n",
    "import pandas as pd\n",
    "flagfiles = pd.read_csv(\"f0_check/Can_flagfiles.csv\")\n",
    "target = \"S3dia1nC4\"\n",
    "\n",
    "print(flagfiles[flagfiles[\"filename\"] == target])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p2fa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
